{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigEarthNet Sets\n",
    "> Functions to quickly access sets and subsets of patch names of BigEarthNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from typing import Sequence, Set, List\n",
    "\n",
    "import fastcore.all as fc\n",
    "from pydantic import ValidationError, validate_arguments\n",
    "import natsort\n",
    "\n",
    "import bigearthnet_common.base as ben_base\n",
    "import bigearthnet_common.constants as ben_constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_all_s2_patches() -> Set[str]:\n",
    "    return set(ben_base.get_complete_s2_to_s1_patch_name_mapping().keys())\n",
    "\n",
    "\n",
    "def get_all_s1_patches() -> Set[str]:\n",
    "    return set(ben_base.get_complete_s1_to_s2_patch_name_mapping().keys())\n",
    "\n",
    "\n",
    "def get_recommended_s2_patches() -> Set[str]:\n",
    "    s2_patches = get_all_s2_patches()\n",
    "    no_19_class_targets = ben_base.get_s2_patches_with_no_19_class_target()\n",
    "    recommended_s2_patches = {\n",
    "        p\n",
    "        for p in s2_patches\n",
    "        if not ben_base.is_snowy_patch(p)\n",
    "        and not ben_base.is_cloudy_shadowy_patch(p)\n",
    "        and p not in no_19_class_targets\n",
    "    }\n",
    "    return recommended_s2_patches\n",
    "\n",
    "\n",
    "def get_recommended_s1_patches() -> Set[str]:\n",
    "    s1_patches = get_all_s1_patches()\n",
    "    no_19_class_targets = ben_base.get_s1_patches_with_no_19_class_target()\n",
    "    recommended_s1_patches = {\n",
    "        p\n",
    "        for p in s1_patches\n",
    "        if not ben_base.is_snowy_patch(p)\n",
    "        and not ben_base.is_cloudy_shadowy_patch(p)\n",
    "        and p not in no_19_class_targets\n",
    "    }\n",
    "    return recommended_s1_patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(get_all_s1_patches()) == ben_constants.BEN_COMPLETE_SIZE\n",
    "assert len(get_all_s2_patches()) == ben_constants.BEN_COMPLETE_SIZE\n",
    "assert len(get_recommended_s1_patches()) == ben_constants.BEN_RECOMMENDED_SIZE\n",
    "assert len(get_recommended_s2_patches()) == ben_constants.BEN_RECOMMENDED_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@validate_arguments\n",
    "def filter_s2_patches_by_country(\n",
    "    patches: Sequence, country: ben_constants.Country\n",
    ") -> Set[str]:\n",
    "    if country not in ben_constants.COUNTRIES:\n",
    "        raise ValueError(\n",
    "            f\"{country} is not one of the BEN countries: {ben_constants.COUNTRIES}!\"\n",
    "        )\n",
    "\n",
    "    patch_country_mapping = ben_base.get_patches_to_country_mapping(\n",
    "        use_s2_patch_names=True\n",
    "    )\n",
    "    return {p for p in patches if patch_country_mapping[p] == country}\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_s1_patches_by_country(\n",
    "    patches: Sequence, country: ben_constants.Country\n",
    ") -> Set[str]:\n",
    "    if country not in ben_constants.COUNTRIES:\n",
    "        raise ValueError(\n",
    "            f\"{country} is not one of the BEN countries: {ben_constants.COUNTRIES}!\"\n",
    "        )\n",
    "\n",
    "    patch_country_mapping = ben_base.get_patches_to_country_mapping(\n",
    "        use_s2_patch_names=False\n",
    "    )\n",
    "    return {p for p in patches if patch_country_mapping[p] == country}\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_patches_by_country(\n",
    "    sentinel_source: ben_constants.SentinelSource,\n",
    "    patches: Sequence,\n",
    "    country: ben_constants.Country,\n",
    "):\n",
    "    return (\n",
    "        filter_s1_patches_by_country(patches, country)\n",
    "        if sentinel_source == ben_constants.SentinelSource.S1\n",
    "        else filter_s2_patches_by_country(patches, country)\n",
    "    )\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_s2_patches_by_season(\n",
    "    patches: Sequence, season: ben_constants.Season\n",
    ") -> Set[str]:\n",
    "    patch_season_mapping = ben_base.get_patches_to_season_mapping(\n",
    "        use_s2_patch_names=True\n",
    "    )\n",
    "    return {p for p in patches if patch_season_mapping[p] == season}\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_s1_patches_by_season(\n",
    "    patches: Sequence, season: ben_constants.Season\n",
    ") -> Set[str]:\n",
    "    patch_season_mapping = ben_base.get_patches_to_season_mapping(\n",
    "        use_s2_patch_names=False\n",
    "    )\n",
    "    return {p for p in patches if patch_season_mapping[p] == season}\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_patches_by_season(\n",
    "    sentinel_source: ben_constants.SentinelSource,\n",
    "    patches: Sequence,\n",
    "    season: ben_constants.Season,\n",
    "):\n",
    "    \"\"\"\n",
    "    Given Sentinel-1/2 named-patches, return only those patches that belong to a given\n",
    "    season.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        filter_s1_patches_by_season(patches, season)\n",
    "        if sentinel_source == ben_constants.SentinelSource.S1\n",
    "        else filter_s2_patches_by_season(patches, season)\n",
    "    )\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_s1_patches_by_split(patches: Sequence, split: ben_constants.Split):\n",
    "    get_split_func = {\n",
    "        split.train: ben_base.get_s1_patches_from_original_train_split,\n",
    "        split.validation: ben_base.get_s1_patches_from_original_validation_split,\n",
    "        split.test: ben_base.get_s1_patches_from_original_test_split,\n",
    "    }\n",
    "    split_patches = get_split_func[split]()\n",
    "    return patches & split_patches\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_s2_patches_by_split(patches: Sequence, split: ben_constants.Split):\n",
    "    get_split_func = {\n",
    "        split.train: ben_base.get_s2_patches_from_original_train_split,\n",
    "        split.validation: ben_base.get_s2_patches_from_original_validation_split,\n",
    "        split.test: ben_base.get_s2_patches_from_original_test_split,\n",
    "    }\n",
    "    split_patches = get_split_func[split]()\n",
    "    return set(patches) & split_patches\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def filter_patches_by_split(\n",
    "    sentinel_source: ben_constants.SentinelSource,\n",
    "    patches: Sequence,\n",
    "    split: ben_constants.Split,\n",
    "):\n",
    "    return (\n",
    "        filter_s1_patches_by_split(patches, split)\n",
    "        if sentinel_source == ben_constants.SentinelSource.S1\n",
    "        else filter_s2_patches_by_split(patches, split)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@validate_arguments\n",
    "def build_set(\n",
    "    sentinel_source: ben_constants.SentinelSource,\n",
    "    seasons: List[ben_constants.Season] = [s.value for s in ben_constants.Season],\n",
    "    countries: List[ben_constants.Country] = [c.value for c in ben_constants.Country],\n",
    "    remove_unrecommended_dl_patches: bool = True,\n",
    ") -> Set[str]:\n",
    "    \"\"\"\n",
    "    Create a subset of the Sentinel-1/Sentinel-2 patches.\n",
    "    The returned list will be naturally sorted to produce\n",
    "    deterministic results.\n",
    "    \"\"\"\n",
    "    use_s1 = sentinel_source == ben_constants.SentinelSource.S1\n",
    "    # FUTURE: could be split up into higher level functions\n",
    "    if remove_unrecommended_dl_patches:\n",
    "        patches = (\n",
    "            get_recommended_s1_patches() if use_s1 else get_recommended_s2_patches()\n",
    "        )\n",
    "    else:\n",
    "        patches = get_all_s1_patches() if use_s1 else get_all_s2_patches()\n",
    "\n",
    "    if len(seasons) > 0:\n",
    "        patches = {\n",
    "            patch\n",
    "            for season in seasons\n",
    "            for patch in filter_patches_by_season(sentinel_source, patches, season)\n",
    "        }\n",
    "    if len(countries) > 0:\n",
    "        patches = {\n",
    "            patch\n",
    "            for country in countries\n",
    "            for patch in filter_patches_by_country(sentinel_source, patches, country)\n",
    "        }\n",
    "    return patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# length is independent of S1/S2 source\n",
    "assert len(build_set(\"S1\", seasons=[\"Winter\"])) < len(\n",
    "    build_set(\"S2\", seasons=[\"Winter\", \"Fall\"])\n",
    ")\n",
    "assert len(build_set(\"S1\", countries=[\"Austria\"])) < len(\n",
    "    build_set(\n",
    "        \"S2\", countries=[ben_constants.Country.Austria, ben_constants.Country.Kosovo]\n",
    "    )\n",
    ")\n",
    "assert len(\n",
    "    build_set(\n",
    "        \"S1\",\n",
    "        seasons=[ben_constants.Season.Winter],\n",
    "        remove_unrecommended_dl_patches=True,\n",
    "    )\n",
    ") < len(\n",
    "    build_set(\n",
    "        \"S1\",\n",
    "        seasons=[ben_constants.Season.Winter],\n",
    "        remove_unrecommended_dl_patches=False,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "with fc.ExceptionExpected(ValidationError):\n",
    "    build_set(\"S1\", seasons=ben_constants.Season.Winter)\n",
    "with fc.ExceptionExpected(ValidationError):\n",
    "    build_set(\"S1\", countries=\"winter\")\n",
    "with fc.ExceptionExpected(ValidationError):\n",
    "    build_set(\"S1\", countries=\"wintr\")\n",
    "with fc.ExceptionExpected(ValidationError):\n",
    "    build_set(\"S1\", countries=\"Astria\")\n",
    "with fc.ExceptionExpected(ValidationError):\n",
    "    build_set(\"S1\", countries=\"Norway\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@fc.delegates(build_set)\n",
    "@validate_arguments\n",
    "def build_csv_sets(\n",
    "    file_path: Path,\n",
    "    sentinel_source: ben_constants.SentinelSource,\n",
    "    write_separate_splits: bool = True,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build CSV files that contain Sentinel-1/2 patches names with the given restrictions.\n",
    "    By default, the patches will be grouped by the orignal train/validation/test split.\n",
    "    This is generally a good starting point, but not ideal for all use-cases.\n",
    "    If `write_separate_splits` is `False`, the output will contain all patches.\n",
    "    The generated file does **not** contain a header row, as this style was used in all the other\n",
    "    publicly available BigEarthNet CSV files.\n",
    "\n",
    "    The patch names will be naturally sorted to ensure deterministic outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def _write_csv(fp, patches):\n",
    "        sorted_patches = natsort.natsorted(patches)\n",
    "        with open(fp.with_suffix(\".csv\"), \"w\") as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "            for patch in sorted_patches:\n",
    "                writer.writerow([patch])\n",
    "\n",
    "    patches = build_set(sentinel_source, **kwargs)\n",
    "    if write_separate_splits:\n",
    "        train_patches = filter_patches_by_split(\n",
    "            sentinel_source, patches, ben_constants.Split.train\n",
    "        )\n",
    "        validation_patches = filter_patches_by_split(\n",
    "            sentinel_source, patches, ben_constants.Split.validation\n",
    "        )\n",
    "        test_patches = filter_patches_by_split(\n",
    "            sentinel_source, patches, ben_constants.Split.test\n",
    "        )\n",
    "        assert min(len(train_patches), len(validation_patches), len(test_patches)) > 0\n",
    "        assert (train_patches & validation_patches & test_patches) == set()\n",
    "        _write_csv(file_path.with_name(f\"{file_path.name}_train.csv\"), train_patches)\n",
    "        _write_csv(\n",
    "            file_path.with_name(f\"{file_path.name}_validation.csv\"), validation_patches\n",
    "        )\n",
    "        _write_csv(file_path.with_name(f\"{file_path.name}_test.csv\"), test_patches)\n",
    "    else:\n",
    "        _write_csv(file_path, patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    in_name = \"patches\"\n",
    "    tmp_fp = Path(tmpdirname) / in_name\n",
    "    build_csv_sets(\n",
    "        tmp_fp,\n",
    "        ben_constants.SentinelSource.S2,\n",
    "        seasons=[ben_constants.Season.Summer],\n",
    "        countries=[ben_constants.Country.Serbia],\n",
    "        write_separate_splits=False,\n",
    "    )\n",
    "    assert tmp_fp.with_suffix(\".csv\").exists()\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    in_name = \"patches\"\n",
    "    tmp_fp = Path(tmpdirname) / in_name\n",
    "    build_csv_sets(\n",
    "        tmp_fp,\n",
    "        ben_constants.SentinelSource.S2,\n",
    "        seasons=[ben_constants.Season.Summer],\n",
    "        countries=[ben_constants.Country.Serbia],\n",
    "    )\n",
    "    assert tmp_fp.with_name(f\"{tmp_fp.name}_train.csv\").exists()\n",
    "    assert tmp_fp.with_name(f\"{tmp_fp.name}_validation.csv\").exists()\n",
    "    assert tmp_fp.with_name(f\"{tmp_fp.name}_test.csv\").exists()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import typer\n",
    "\n",
    "\n",
    "def build_csv_sets_cli():\n",
    "    app = typer.Typer(name=\"ben_build_csv_sets\")\n",
    "    app.command()(build_csv_sets)\n",
    "    app()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" and not fc.IN_IPYTHON:\n",
    "    build_csv_sets_cli()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_constants.ipynb.\n",
      "Converted 01_base.ipynb.\n",
      "Converted 02_sets.ipynb.\n",
      "Converted index.ipynb.\n",
      "converting: /home/kai/git/bigearthnet_common/nbs/01_base.ipynb\n",
      "converting: /home/kai/git/bigearthnet_common/nbs/02_sets.ipynb\n",
      "converting /home/kai/git/bigearthnet_common/nbs/index.ipynb to README.md\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.cli import nbdev_build_docs\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n",
    "nbdev_build_docs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('bigearthnet-common-gsn-YR4P-py3.9': poetry)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
